{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "proj_path = Path('/cluster') / 'work' / 'stefandt' / 'pers-pred'\n",
    "proj_path = proj_path.resolve()\n",
    "if proj_path not in sys.path: sys.path.append(str(proj_path))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils import get_commons\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 11:36:18,766 - ArgumentLogger - INFO - Arguments:\n",
      "2024-05-24 11:36:18,768 - ArgumentLogger - INFO - dataframe: {'generate': False, 'mbti_frac': 0.1, 'bigfive_c_frac': 1.0, 'bigfive_s_frac': 1.0}\n",
      "2024-05-24 11:36:18,768 - ArgumentLogger - INFO - eda: {'generate': False}\n",
      "2024-05-24 11:36:18,769 - ArgumentLogger - INFO - reduce: {'generate': False, 'use_full': False}\n",
      "2024-05-24 11:36:18,770 - ArgumentLogger - INFO - preprocessing: {'generate_features': False, 'generate_partially_cleaned': False, 'generate_cleaned': False, 'generate_embeddings': False, 'generate_aggregated': True, 'generate_glove': False, 'generate_filled': True, 'model_name': 'distilbert'}\n",
      "2024-05-24 11:36:18,771 - ArgumentLogger - INFO - dataloaders: {'train': {'num_workers': 1, 'pin_memory': False, 'batch_size': 1028, 'shuffle': True, 'drop_last': True}, 'test': {'num_workers': 1, 'pin_memory': False, 'batch_size': 1028, 'shuffle': False, 'drop_last': False}}\n",
      "2024-05-24 11:36:18,771 - ArgumentLogger - INFO - split: {'generate': True, 'train_size': 0.8, 'test_size': 0.1}\n",
      "2024-05-24 11:36:18,772 - ArgumentLogger - INFO - tokenizer: {'do_lower_case': True, 'padding_side': 'right', 'truncation_side': 'right', 'max_length': 128, 'padding': 'max_length', 'truncation': True}\n",
      "2024-05-24 11:36:18,773 - ArgumentLogger - INFO - model: {'hidden_sizes': [1024, 512], 'dropout': 0.3}\n",
      "2024-05-24 11:36:18,774 - ArgumentLogger - INFO - training: {'checkpoint_name': 'adamp-test', 'n_epochs': 400, 'early_stopping_window': 20}\n",
      "2024-05-24 11:36:18,775 - ArgumentLogger - INFO - optimizer: {'name': 'adam', 'lr': 0.0001, 'betas': [0.9, 0.999], 'weight_decay': 0.01}\n",
      "2024-05-24 11:36:18,776 - ArgumentLogger - INFO - mtl: {'weighting': 'GradNorm', 'architecture': 'HPS', 'optim_param': {'optim': 'adam', 'lr': 0.001, 'weight_decay': 0.0001}, 'scheduler_param': {}, 'kwargs': {'weight_args': {'alpha': 1.5}, 'arch_args': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "paths, constants, config, logger, device = get_commons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "for task in constants[\"tasks\"]:\n",
    "    data = pd.read_csv(paths[\"split\"][\"distilbert\"][task], header=[0, 1], index_col=0)\n",
    "    data[\"TASK\", task] = True\n",
    "    datas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(datas, copy=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73156/3397032738.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"TASK\"] = data[\"TASK\"].fillna(False)\n",
      "/tmp/ipykernel_73156/3397032738.py:1: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  data[\"TASK\"] = data[\"TASK\"].fillna(False)\n",
      "/tmp/ipykernel_73156/3397032738.py:1: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  data[\"TASK\"] = data[\"TASK\"].fillna(False)\n",
      "/tmp/ipykernel_73156/3397032738.py:1: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  data[\"TASK\"] = data[\"TASK\"].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "data[\"TASK\"] = data[\"TASK\"].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = [[\"TARGET\", big] for big in constants[\"bigfive_c_columns\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(drops, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>FEATURE</th>\n",
       "      <th>mbtiEXT</th>\n",
       "      <th>mbtiJUD</th>\n",
       "      <th>mbtiSEN</th>\n",
       "      <th>mbtiTHI</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sOPN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUTHOR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-9221022384933360074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9220031623198266213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9219633155989415906</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9219237589017844173</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9214568075844254832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154871534596062825</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157088328270352664</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183557572572801954</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186055652387137827</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9205889454282744177</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21647 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "FEATURE               mbtiEXT  mbtiJUD  mbtiSEN  mbtiTHI  sAGR  sCON  sEXT  \\\n",
       "AUTHOR                                                                       \n",
       "-9221022384933360074      0.0      0.0      0.0      1.0   NaN   NaN   NaN   \n",
       "-9220031623198266213      0.0      1.0      1.0      1.0   NaN   NaN   NaN   \n",
       "-9219633155989415906      0.0      0.0      0.0      1.0   NaN   NaN   NaN   \n",
       "-9219237589017844173      0.0      0.0      0.0      0.0   NaN   NaN   NaN   \n",
       "-9214568075844254832      0.0      0.0      0.0      1.0   NaN   NaN   NaN   \n",
       "...                       ...      ...      ...      ...   ...   ...   ...   \n",
       " 9154871534596062825      NaN      NaN      NaN      NaN  11.0  63.0  89.0   \n",
       " 9157088328270352664      NaN      NaN      NaN      NaN  15.0  18.0  12.0   \n",
       " 9183557572572801954      NaN      NaN      NaN      NaN  17.0  35.0  25.0   \n",
       " 9186055652387137827      NaN      NaN      NaN      NaN  10.0  94.0  18.0   \n",
       " 9205889454282744177      NaN      NaN      NaN      NaN  91.0  21.0  42.0   \n",
       "\n",
       "FEATURE               sNEU  sOPN  \n",
       "AUTHOR                            \n",
       "-9221022384933360074   NaN   NaN  \n",
       "-9220031623198266213   NaN   NaN  \n",
       "-9219633155989415906   NaN   NaN  \n",
       "-9219237589017844173   NaN   NaN  \n",
       "-9214568075844254832   NaN   NaN  \n",
       "...                    ...   ...  \n",
       " 9154871534596062825   9.0  78.0  \n",
       " 9157088328270352664  19.0  30.0  \n",
       " 9183557572572801954  84.0   9.0  \n",
       " 9186055652387137827  66.0  84.0  \n",
       " 9205889454282744177  32.0  61.0  \n",
       "\n",
       "[21647 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73156/3573377885.py:93: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  y_true = complete_rows[('TARGET', mbti_dimension)].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 103\u001b[0m\n\u001b[1;32m     95\u001b[0m     big_five_scores \u001b[39m=\u001b[39m complete_rows[select]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     96\u001b[0m     y_scores \u001b[39m=\u001b[39m [predict_mbti({\n\u001b[1;32m     97\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mNeuroticism\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m0\u001b[39m],\n\u001b[1;32m     98\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExtraversion\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mConscientiousness\u001b[39m\u001b[39m'\u001b[39m: row[\u001b[39m4\u001b[39m]\n\u001b[1;32m    102\u001b[0m     })[mbti_dimension[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:]] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m big_five_scores]\n\u001b[0;32m--> 103\u001b[0m     optimal_thresholds[mbti_dimension[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:]] \u001b[39m=\u001b[39m find_optimal_threshold(y_true, y_scores)\n\u001b[1;32m    105\u001b[0m \u001b[39m# Fill missing values in the DataFrame\u001b[39;00m\n\u001b[1;32m    106\u001b[0m df_filled \u001b[39m=\u001b[39m fill_missing_values(data, optimal_thresholds)\n",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m, in \u001b[0;36mfind_optimal_threshold\u001b[0;34m(y_true, y_scores)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_optimal_threshold\u001b[39m(y_true, y_scores):\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(y_true, y_scores)\n\u001b[0;32m---> 20\u001b[0m     fpr, tpr, thresholds \u001b[39m=\u001b[39m roc_curve(y_true, y_scores)\n\u001b[1;32m     21\u001b[0m     youden_j \u001b[39m=\u001b[39m tpr \u001b[39m-\u001b[39m fpr\n\u001b[1;32m     22\u001b[0m     optimal_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(youden_j)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppconda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppconda/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1108\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   1007\u001b[0m     {\n\u001b[1;32m   1008\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m ):\n\u001b[1;32m   1019\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \n\u001b[1;32m   1021\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m   1109\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39mpos_label, sample_weight\u001b[39m=\u001b[39msample_weight\n\u001b[1;32m   1110\u001b[0m     )\n\u001b[1;32m   1112\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ppconda/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:817\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    815\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m--> 817\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m    819\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    820\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: unknown format is not supported"
     ]
    }
   ],
   "source": [
    "# Regression coefficients from the provided tables\n",
    "coefficients = {\n",
    "    'EI': {'Neuroticism': -0.01, 'Extraversion': 0.16, 'Openness': 0.00, 'Agreeableness': 0.02, 'Conscientiousness': -0.01},\n",
    "    'SN': {'Neuroticism': -0.02, 'Extraversion': -0.01, 'Openness': -0.03, 'Agreeableness': 0.05, 'Conscientiousness': -0.05},\n",
    "    'TF': {'Neuroticism': -0.12, 'Extraversion': -0.04, 'Openness': -0.08, 'Agreeableness': -0.39, 'Conscientiousness': 0.17},\n",
    "    'JP': {'Neuroticism': 0.04, 'Extraversion': -0.02, 'Openness': -0.11, 'Agreeableness': 0.03, 'Conscientiousness': 0.13}\n",
    "}\n",
    "\n",
    "# Function to predict MBTI scores from Big Five scores\n",
    "def predict_mbti(big_five_scores):\n",
    "    mbti_scores = {}\n",
    "    for mbti, coeffs in coefficients.items():\n",
    "        score = sum(big_five_scores[trait] * coeff for trait, coeff in coeffs.items())\n",
    "        mbti_scores[mbti] = score\n",
    "    return mbti_scores\n",
    "\n",
    "# Function to find the optimal threshold using Youden's J statistic\n",
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    print(y_true, y_scores)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Function to convert MBTI scores to binary labels using optimal thresholds\n",
    "def mbti_to_binary_with_thresholds(mbti_scores, optimal_thresholds):\n",
    "    binary_labels = {}\n",
    "    for dimension, score in mbti_scores.items():\n",
    "        binary_labels[dimension] = 1 if score > optimal_thresholds[dimension] else 0\n",
    "    return binary_labels\n",
    "\n",
    "# Function to predict Big Five scores from MBTI scores\n",
    "def predict_big_five(mbti_scores):\n",
    "    # Create a matrix of coefficients\n",
    "    coeff_matrix = np.array([\n",
    "        [coefficients['EI']['Neuroticism'], coefficients['EI']['Extraversion'], coefficients['EI']['Openness'], coefficients['EI']['Agreeableness'], coefficients['EI']['Conscientiousness']],\n",
    "        [coefficients['SN']['Neuroticism'], coefficients['SN']['Extraversion'], coefficients['SN']['Openness'], coefficients['SN']['Agreeableness'], coefficients['SN']['Conscientiousness']],\n",
    "        [coefficients['TF']['Neuroticism'], coefficients['TF']['Extraversion'], coefficients['TF']['Openness'], coefficients['TF']['Agreeableness'], coefficients['TF']['Conscientiousness']],\n",
    "        [coefficients['JP']['Neuroticism'], coefficients['JP']['Extraversion'], coefficients['JP']['Openness'], coefficients['JP']['Agreeableness'], coefficients['JP']['Conscientiousness']]\n",
    "    ])\n",
    "    \n",
    "    # Create a vector of MBTI scores\n",
    "    mbti_vector = np.array([mbti_scores['EI'], mbti_scores['SN'], mbti_scores['TF'], mbti_scores['JP']])\n",
    "    \n",
    "    # Solve the linear system to find Big Five scores\n",
    "    big_five_scores = np.linalg.lstsq(coeff_matrix, mbti_vector, rcond=None)[0]\n",
    "    \n",
    "    # Map the results to the Big Five traits\n",
    "    big_five_traits = ['Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness']\n",
    "    big_five_dict = {trait: score for trait, score in zip(big_five_traits, big_five_scores)}\n",
    "    \n",
    "    return big_five_dict\n",
    "\n",
    "# Function to fill missing values in the DataFrame\n",
    "def fill_missing_values(df, optimal_thresholds):\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row[('TARGET', 'mbtiEXT')]):\n",
    "            big_five_scores = {\n",
    "                'Neuroticism': row[('TARGET', 'sNEU')],\n",
    "                'Extraversion': row[('TARGET', 'sEXT')],\n",
    "                'Openness': row[('TARGET', 'sOPN')],\n",
    "                'Agreeableness': row[('TARGET', 'cAGR')],\n",
    "                'Conscientiousness': row[('TARGET', 'sCON')]\n",
    "            }\n",
    "            predicted_mbti = predict_mbti(big_five_scores)\n",
    "            binary_mbti = mbti_to_binary_with_thresholds(predicted_mbti, optimal_thresholds)\n",
    "            df.at[index, ('TARGET', 'mbtiEXT')] = binary_mbti['EI']\n",
    "            df.at[index, ('TARGET', 'mbtiJUD')] = binary_mbti['JP']\n",
    "            df.at[index, ('TARGET', 'mbtiSEN')] = binary_mbti['SN']\n",
    "            df.at[index, ('TARGET', 'mbtiTHI')] = binary_mbti['TF']\n",
    "        elif pd.isna(row[('TARGET', 'sNEU')]):\n",
    "            mbti_scores = {\n",
    "                'EI': row[('TARGET', 'mbtiEXT')],\n",
    "                'SN': row[('TARGET', 'mbtiSEN')],\n",
    "                'TF': row[('TARGET', 'mbtiTHI')],\n",
    "                'JP': row[('TARGET', 'mbtiJUD')]\n",
    "            }\n",
    "            big_five_scores = predict_big_five(mbti_scores)\n",
    "            df.at[index, ('TARGET', 'sNEU')] = big_five_scores['Neuroticism']\n",
    "            df.at[index, ('TARGET', 'sEXT')] = big_five_scores['Extraversion']\n",
    "            df.at[index, ('TARGET', 'sOPN')] = big_five_scores['Openness']\n",
    "            df.at[index, ('TARGET', 'cAGR')] = big_five_scores['Agreeableness']\n",
    "            df.at[index, ('TARGET', 'sCON')] = big_five_scores['Conscientiousness']\n",
    "    return df\n",
    "\n",
    "# Extract rows with both MBTI and Big Five scores\n",
    "complete_rows = data.dropna()\n",
    "\n",
    "# Calculate optimal thresholds for each MBTI dimension using complete rows\n",
    "optimal_thresholds = {}\n",
    "for mbti_dimension in ['mbtiEXT', 'mbtiJUD', 'mbtiSEN', 'mbtiTHI']:\n",
    "    y_true = complete_rows[('TARGET', mbti_dimension)].values\n",
    "    select = [[\"TARGET\", big] for big in constants[\"bigfive_s_columns\"]]\n",
    "    big_five_scores = complete_rows[select].values\n",
    "    y_scores = [predict_mbti({\n",
    "        'Neuroticism': row[0],\n",
    "        'Extraversion': row[1],\n",
    "        'Openness': row[2],\n",
    "        'Agreeableness': row[3],\n",
    "        'Conscientiousness': row[4]\n",
    "    })[mbti_dimension[-3:]] for row in big_five_scores]\n",
    "    optimal_thresholds[mbti_dimension[-3:]] = find_optimal_threshold(y_true, y_scores)\n",
    "\n",
    "# Fill missing values in the DataFrame\n",
    "df_filled = fill_missing_values(data, optimal_thresholds)\n",
    "\n",
    "print(df_filled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
