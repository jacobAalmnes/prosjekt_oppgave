{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "proj_path = Path('/cluster') / 'work' / 'stefandt' / 'pers-pred'\n",
    "proj_path = proj_path.resolve()\n",
    "if proj_path not in sys.path: sys.path.append(str(proj_path))\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "from src.utils import get_commons\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from fcmeans import FCM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, constants, config, logger, device = get_commons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora_authors = pd.read_csv(paths['raw']['pandora_authors'])\n",
    "pandora_comments = pd.read_csv(paths['raw']['pandora_comments'])\n",
    "pandora_authors = pandora_authors.rename({\n",
    "        'author': 'AUTHOR', \n",
    "        'introverted': 'mbtiEXT', # Flip\n",
    "        'intuitive': 'mbtiSEN', # Flip\n",
    "        'thinking': 'mbtiTHI', \n",
    "        'perceiving': 'mbtiJUD', # Flip \n",
    "        'agreeableness': 'sAGR', \n",
    "        'openness': 'sOPN', \n",
    "        'conscientiousness': 'sCON', \n",
    "        'extraversion': 'sEXT',\n",
    "        'neuroticism': 'sNEU'\n",
    "    },\n",
    "axis ='columns')\n",
    "pandora_authors[['mbtiEXT', 'mbtiSEN', 'mbtiJUD']] = 1 - pandora_authors[['mbtiEXT', 'mbtiSEN', 'mbtiJUD']]\n",
    "pandora_authors['gender'] = pandora_authors['gender'].map({'m': True, 'f': False}).astype('boolean')\n",
    "pandora_comments = pandora_comments.rename({\n",
    "        'author': 'AUTHOR',\n",
    "        'body': 'TEXT'\n",
    "    },\n",
    "axis='columns')\n",
    "pandora2 = pd.merge(pandora_authors, pandora_comments, on='AUTHOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(actual, predicted):\n",
    "    return np.sqrt(((actual - predicted) ** 2).mean())\n",
    "\n",
    "def find_optimal_k(X, y, k_values):\n",
    "    errors = []\n",
    "    for k in k_values:\n",
    "        nbrs = NearestNeighbors(n_neighbors=k).fit(X)\n",
    "        distances, indices = nbrs.kneighbors(X)\n",
    "        imputed_values = np.mean(y[indices], axis=1)\n",
    "        rmse = calculate_rmse(y, imputed_values)\n",
    "        errors.append(rmse)\n",
    "    optimal_k = k_values[np.argmin(errors)]\n",
    "    return optimal_k\n",
    "\n",
    "def knn_iterative_imputation(df, target_cols, k_values):\n",
    "    imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "    numeric_data = df.select_dtypes(include=[np.number])\n",
    "    for col in target_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            X_complete = numeric_data.dropna(subset=[col])\n",
    "            y_complete = X_complete[col]\n",
    "            X_complete = X_complete.drop(columns=target_cols)\n",
    "            X_missing = numeric_data[numeric_data[col].isnull()].drop(columns=target_cols)\n",
    "            optimal_k = find_optimal_k(X_complete, y_complete, k_values)\n",
    "            nbrs = NearestNeighbors(n_neighbors=optimal_k).fit(X_complete)\n",
    "            distances, indices = nbrs.kneighbors(X_missing)\n",
    "            imputed_values = np.mean(y_complete.values[indices], axis=1)\n",
    "            df.loc[df[col].isnull(), col] = imputed_values\n",
    "    numeric_imputed_data = pd.DataFrame(imputer.fit_transform(numeric_data), columns=numeric_data.columns)\n",
    "    df[numeric_data.columns] = numeric_imputed_data\n",
    "    return df\n",
    "\n",
    "def fcki_imputation(df, target_cols, c_clusters, k_values):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    relevant_cols = [col for col in numeric_cols if col not in target_cols]\n",
    "    fcm = FCM(n_clusters=c_clusters)\n",
    "    fcm.fit(df[relevant_cols].values)\n",
    "    labels = fcm.predict(df[relevant_cols].values)\n",
    "    imputed_data = df.copy()\n",
    "    for cluster in np.unique(labels):\n",
    "        cluster_data = df[labels == cluster]\n",
    "        imputed_cluster_data = knn_iterative_imputation(cluster_data, target_cols, k_values)\n",
    "        imputed_data.loc[labels == cluster] = imputed_cluster_data\n",
    "        # Clear memory\n",
    "        del cluster_data, imputed_cluster_data\n",
    "        gc.collect()\n",
    "    return imputed_data\n",
    "\n",
    "def calculate_wcss(data):\n",
    "    wcss = []\n",
    "    for k in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    return wcss\n",
    "\n",
    "def plot_elbow(wcss):\n",
    "    plt.plot(range(1, 11), wcss)\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "target_cols = ['mbtiEXT', 'mbtiSEN', 'mbtiTHI', 'mbtiJUD', 'sAGR', 'sOPN', 'sCON', 'sEXT', 'sNEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset without missing values\n",
    "subset = pandora.dropna(subset=target_cols)\n",
    "\n",
    "# Fill missing values in numeric columns with the mean of the subset\n",
    "numeric_cols = subset.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "if False:\n",
    "    subset = pandora.dropna(subset=target_cols)\n",
    "\n",
    "    numeric_cols = subset.select_dtypes(include=[np.number]).columns\n",
    "    subset[numeric_cols] = subset[numeric_cols].fillna(subset[numeric_cols].mean())\n",
    "\n",
    "    relevant_cols = [col for col in numeric_cols if col not in target_cols]\n",
    "\n",
    "    wcss = calculate_wcss(subset[relevant_cols].values)\n",
    "    plot_elbow(wcss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_clusters = 3 \n",
    "k_values = range(2, 11)\n",
    "\n",
    "# Apply FCKI imputation\n",
    "# Ensure all necessary columns are filled with mean values before clustering\n",
    "pandora[numeric_cols] = pandora[numeric_cols].fillna(pandora[numeric_cols].mean())\n",
    "imputed_data_fcki = fcki_imputation(pandora, target_cols, c_clusters, k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_fcki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pandora = Path('/cluster') / 'work' / 'stefandt' / 'pers-pred' / 'data' / 'filled' / 'pandora.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora.to_csv(path_pandora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora.loc[pandora['AUTHOR'] == '-BigSexy-'][target_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora = pd.read_csv(path_pandora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pand_cols = constants['bigfive_s_columns'] + constants['mbti_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora[pand_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora[constants['mbti_columns']] = (pandora[constants['mbti_columns']] > 0.5).astype(int)\n",
    "pandora[constants['bigfive_c_columns']] = (pandora[constants['bigfive_s_columns']] > 50).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora[constants['label_columns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora.loc[pandora['cEXT'] != pandora['mbtiEXT']].groupby('AUTHOR')[constants['label_columns']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora2 = pandora2.dropna(subset=pand_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora2[constants['bigfive_c_columns']] = (pandora2[constants['bigfive_s_columns']] > 50).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora2.groupby('AUTHOR')[constants['label_columns']].mean().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora2.loc[pandora2['cEXT'] != pandora2['mbtiEXT']].groupby('AUTHOR')[constants['label_columns']].mean().shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
