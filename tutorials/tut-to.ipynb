{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tensors\n",
    "\n",
    "Basicly numpy arrays, but allow for parallelization and quick gradient computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = [\n",
    "  [1, 2, 3],\n",
    "  [4, 5, 6]\n",
    "]\n",
    "\n",
    "data = torch.tensor([\n",
    "  [0, 1],\n",
    "  [2, 3],\n",
    "  [4, 5], \n",
    "])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([\n",
    "  [0, 1],\n",
    "  [2, 3],\n",
    "  [4, 5]\n",
    "], dtype=torch.float32)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(2,5)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(2,5)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr = torch.arange(1,10)\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  4,  6,  8, 10, 12, 14, 16, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  8, 12, 16, 20, 24, 28, 32, 36])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 14, 17, 20],\n",
      "        [17, 22, 27, 32],\n",
      "        [29, 38, 47, 56]])\n",
      "tensor([[11, 14, 17, 20],\n",
      "        [17, 22, 27, 32],\n",
      "        [29, 38, 47, 56]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2], [2,3], [4,5]])\n",
    "b = torch.tensor([[1,2,3,4],[5,6,7,8]]) \n",
    "\n",
    "print(a.matmul(b))\n",
    "\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: torch.Size([3, 2])\n",
      "B: torch.Size([2, 4])\n",
      "A@B: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f'A: {a.shape}')\n",
    "print(f'B: {b.shape}')\n",
    "print(f'A@B: {(a@b).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "torch.Size([5, 3])\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12],\n",
      "        [13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "rr = torch.arange(1, 16)\n",
    "print(rr.shape)\n",
    "\n",
    "rr = rr.reshape(5, 3)\n",
    "print(rr.shape)\n",
    "print(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is:  tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18., 19., 20., 21.],\n",
      "        [22., 23., 24., 25., 26., 27., 28.],\n",
      "        [29., 30., 31., 32., 33., 34., 35.]])\n",
      "Taking sum over columns:\n",
      "tensor([ 75.,  80.,  85.,  90.,  95., 100., 105.])\n",
      "Taking sum over rows:\n",
      "tensor([ 28.,  77., 126., 175., 224.])\n",
      "Taking the stdev over rows:\n",
      "tensor([2.1602, 2.1602, 2.1602, 2.1602, 2.1602])\n"
     ]
    }
   ],
   "source": [
    "data = torch.arange(1, 36, dtype=torch.float32).reshape(5,7)\n",
    "print(\"Data is: \", data)\n",
    "\n",
    "\n",
    "print(\"Taking sum over columns:\")\n",
    "print(data.sum(dim=0))\n",
    "\n",
    "print(\"Taking sum over rows:\")\n",
    "print(data.sum(dim=1))\n",
    "\n",
    "print(\"Taking the stdev over rows:\")\n",
    "print(data.std(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dim we specify when performing these aggregating functions is the one that gets eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 7,  8]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,13)\n",
    "x = x.view(3, 2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :] # Providing a colon for a dim means \"copy over that dim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2],\n",
       "        [ 5,  6],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  3],\n",
       "        [ 5,  7],\n",
       "        [ 9, 11]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16],\n",
       "        [17, 18, 19, 20]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1, 21)\n",
    "y = y.view(5, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [17, 18, 19, 20]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[[0, 2, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differantion feature. We call `backward()` for Pytorch to calculate the gradients, which are then stored in the `grad` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# requires_grad tells pytorch to store gradients\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "pp.pprint(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.])\n"
     ]
    }
   ],
   "source": [
    "y = x * x * 3\n",
    "y.backward()\n",
    "pp.pprint(x.grad) # d(y)/d(x) = d(3x²)/d(x) = 6x = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients are accumilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24.])\n"
     ]
    }
   ],
   "source": [
    "z = x * x * 3\n",
    "z.backward()\n",
    "pp.pprint(x.grad) # d(y)/d(x) = d(3x²)/d(x) = 6x = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we should call `zero_grad` after updating our loss.. In order for loss of last epoch to not influence next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(H_in, H_out)` layer takes matrix `(N, *, H_in)` and outputs `(N, *, H_out)`. We typically consider the first dim `N` to be the batch dimension (i.e number of images, sentences, sequences). The star `*` indicates an arbitrary number of dimensions (i.e with images it could be two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1643, 0.1309],\n",
       "         [0.1643, 0.1309],\n",
       "         [0.1643, 0.1309]],\n",
       "\n",
       "        [[0.1643, 0.1309],\n",
       "         [0.1643, 0.1309],\n",
       "         [0.1643, 0.1309]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.ones(2,3,6) # Last dim has to match first dim of nn\n",
    "\n",
    "linear = nn.Linear(6,2)\n",
    "linear_output = linear(input)\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2248,  0.3835, -0.2953, -0.4049,  0.2233, -0.3593],\n",
       "         [ 0.1114, -0.2636, -0.3103,  0.3189,  0.3827, -0.2263]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3921, 0.1181], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear.parameters()) # Ax + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Layers together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5687, 0.4062],\n",
       "         [0.5687, 0.4062],\n",
       "         [0.5687, 0.4062]],\n",
       "\n",
       "        [[0.5687, 0.4062],\n",
       "         [0.5687, 0.4062],\n",
       "         [0.5687, 0.4062]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = nn.Sequential(\n",
    "  nn.Linear(4,2),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "input = torch.ones(2,3,4)\n",
    "output = block(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom\n",
    "\n",
    "Two things we need to define:\n",
    "1. `__init__()`\n",
    "2. `forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super(MultilayerPerceptron, self).__init__()\n",
    "\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(self.input_size, self.hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(self.hidden_size, self.input_size),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    output = self.model(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3983, 0.5325, 0.3171, 0.5198, 0.5501],\n",
       "        [0.4292, 0.4734, 0.4168, 0.5798, 0.5391]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 5)\n",
    "model = MultilayerPerceptron(5, 3)\n",
    "\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8202,  0.3334,  1.5684,  1.3698, -1.1681],\n",
       "        [ 1.6039,  1.1667,  1.6924,  0.3294,  0.0083],\n",
       "        [ 3.1038,  0.9461, -0.7384,  2.8090,  0.5961],\n",
       "        [-0.0885,  0.6835,  0.3907, -0.5256, -0.4597],\n",
       "        [ 1.8637,  1.4084,  2.0956, -0.9121,  2.5693],\n",
       "        [ 1.2722,  2.8229,  1.6460,  0.0969,  0.8227],\n",
       "        [ 0.1217,  1.1368,  1.1102, -0.0041,  1.4713],\n",
       "        [ 0.4187,  1.4662,  0.4943,  1.6735,  1.7179],\n",
       "        [ 1.3104,  1.4895,  1.9534,  0.9505,  1.5441],\n",
       "        [-0.3242,  0.9450,  0.8084,  1.6520,  0.3484]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need some loss\n",
    "# We pass our model params to the optimizer\n",
    "\n",
    "y = torch.ones(10, 5)\n",
    "x = y + torch.randn_like(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laptop/Code/perspred/pp-venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8443832397460938"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultilayerPerceptron(5,3)\n",
    "\n",
    "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "y_pred = model(x)\n",
    "lossy = loss_function(y_pred, y).item()\n",
    "lossy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss: 0.8443832397460938\n",
      "Epoch 1: Training loss: 0.6940587759017944\n",
      "Epoch 2: Training loss: 0.5450963377952576\n",
      "Epoch 3: Training loss: 0.3767665922641754\n",
      "Epoch 4: Training loss: 0.23145557940006256\n",
      "Epoch 5: Training loss: 0.13198724389076233\n",
      "Epoch 6: Training loss: 0.07587195187807083\n",
      "Epoch 7: Training loss: 0.0481712780892849\n",
      "Epoch 8: Training loss: 0.03338877856731415\n",
      "Epoch 9: Training loss: 0.024316351860761642\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "  adam.zero_grad()\n",
    "  y_pred = model(x)\n",
    "  loss = loss_function(y_pred, y)\n",
    "  print(f\"Epoch {epoch}: Training loss: {loss}\")\n",
    "  loss.backward()\n",
    "  adam.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
